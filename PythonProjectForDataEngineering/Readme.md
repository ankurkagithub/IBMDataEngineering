
# Bank ETL Project

This project performs ETL (Extract, Transform, Load) operations on a dataset of the largest banks by total assets. The data is scraped from a Wikipedia page, processed using exchange rate data, and stored in both CSV and SQLite database formats.

## Features

- **Web Scraping**: Extracts bank data from a Wikipedia article using BeautifulSoup.
- **Data Cleaning & Transformation**: Handles nulls and converts monetary values using exchange rates.
- **Data Storage**:
  - CSV file (`Largest_banks_data.csv`)
  - SQLite database (`Banks.db`) with a table named `Largest_banks`
- **Logging**: Logs each step and errors into `code_log.txt`.

## Requirements

Install dependencies using pip:

```bash
pip install -r requirements.txt
```

If `requirements.txt` is missing, manually install:

```bash
pip install pandas requests beautifulsoup4
```

## Files

- `bank_project.py`: Main script performing the ETL pipeline.
- `exchange_rate.csv`: CSV containing currency exchange rates.
- `Largest_banks_data.csv`: Output file with processed bank data.
- `Banks.db`: SQLite database containing the final table.
- `code_log.txt`: Log file that tracks script operations.

## How to Run

1. Ensure you have internet access (for scraping).
2. Place `exchange_rate.csv` in the same directory as the script.
3. Run the script:

```bash
python bank_project.py
```

After running, check the output files: CSV, SQLite DB, and log.

## Notes

- Make sure the Wikipedia page is accessible. If the live page fails, the script uses an archived URL.
- The script includes error handling and logs all major actions and exceptions.

## Author

Generated by ChatGPT based on the provided `bank_project.py` script.

